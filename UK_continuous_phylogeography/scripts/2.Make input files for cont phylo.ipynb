{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import datetime as dt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_date(date):\n",
    "    year = date.year\n",
    "    if year == 2020:\n",
    "        div = 366\n",
    "    else:\n",
    "        div = 365\n",
    "    start = dt.date(year=year, month=1, day=1)\n",
    "    decimal = (date - start).days/div\n",
    "\n",
    "    dec_date = year + decimal\n",
    "    \n",
    "    return dec_date      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_bit(min_x, min_y, max_x, max_y, polygon, pc, count):\n",
    "    \n",
    "    point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n",
    "\n",
    "    if polygon.contains(point):\n",
    "        return point\n",
    "    else:\n",
    "        count += 1\n",
    "        return recur_bit(min_x, min_y, max_x, max_y, polygon, pc, count)\n",
    "        \n",
    "def find_point(polygon, pc):\n",
    "    count = 0\n",
    "    min_x, min_y, max_x, max_y = polygon.bounds\n",
    "    point = recur_bit(min_x, min_y, max_x, max_y, polygon, pc, count)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## prep postcode data\n",
    "pc_map = gpd.read_file(\"../../Data/UK_geog_data/England_postcode_districts.json\")\n",
    "pc_map.crs = \"epsg:27700\"\n",
    "pc_map = pc_map.to_crs(\"epsg:4326\")\n",
    "\n",
    "dist_to_polygon = {}\n",
    "for dist, geom in zip(pc_map[\"PostDist\"], pc_map[\"geometry\"]):\n",
    "    dist_to_polygon[dist] = geom\n",
    "\n",
    "dist_to_polygon[\"E20\"] = dist_to_polygon[\"E15\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## five largest lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_files(intro_dir, wanted_intros,metadata, outdir):\n",
    "\n",
    "    lin_to_taxa = defaultdict(list)\n",
    "    all_taxa = set()\n",
    "    tax_to_fullname = {}\n",
    "    \n",
    "    for intro_list in os.listdir(intro_dir):\n",
    "        if intro_list.endswith(\".tsv\"):\n",
    "            tree_number = intro_list.split(\".\")[0].split(\"_\")[1][-1]\n",
    "            relevant_intros = [i for i in wanted_intros if i.startswith(tree_number)]\n",
    "            with open(os.path.join(intro_dir,intro_list)) as f:\n",
    "                data = csv.DictReader(f, delimiter=\"\\t\")\n",
    "                for line in data:\n",
    "                    if f\"{tree_number}_{line['lineage']}\" in relevant_intros:\n",
    "                        taxa = line['taxa'].split(\";\")\n",
    "                        for i in taxa:\n",
    "                            lin_to_taxa[f\"{tree_number}_{line['lineage']}\"].append(i.strip(\" \"))\n",
    "                            all_taxa.add(i.strip(\" \").split(\"|\")[0])\n",
    "                            tax_to_fullname[i.strip(\" \").split(\"|\")[0]] = i.strip(\" \")\n",
    "                    \n",
    "    taxa_to_postcode = {}\n",
    "    with open(metadata) as f:\n",
    "        data = csv.DictReader(f)\n",
    "        print(data.fieldnames)\n",
    "        for line in tqdm.tqdm(data):\n",
    "            if line['sequence_name'] in all_taxa:\n",
    "                if line['outer_postcode'] != \"\":\n",
    "                    taxa_to_postcode[line['sequence_name']] = line['outer_postcode']\n",
    "                    \n",
    "    tax_to_coord = {}\n",
    "    for tax, pc in tqdm.tqdm(taxa_to_postcode.items()):\n",
    "        try:\n",
    "            polygon = dist_to_polygon[pc]\n",
    "        except:\n",
    "            continue\n",
    "        point = find_point(polygon, pc)\n",
    "        tax_to_coord[tax] = point\n",
    "        \n",
    "    ##make traits file\n",
    "    for lin, taxa in lin_to_taxa.items():\n",
    "        file_name = f'{outdir}/{lin}_traits.tsv'\n",
    "        with open(file_name, 'w') as fw:\n",
    "            fw.write(\"taxon\\tlatitude\\tlongitude\\n\")\n",
    "            for tax in taxa:\n",
    "                lookup = tax.split(\"|\")[0]\n",
    "                if lookup in tax_to_coord:\n",
    "                    date_str = tax.split(\"|\")[1]\n",
    "                    date = decimal_date(dt.datetime.strptime(date_str, \"%Y-%m-%d\").date())\n",
    "\n",
    "                    fw.write(f\"{tax}\\t{tax_to_coord[lookup].y}\\t{tax_to_coord[lookup].x}\\n\")\n",
    "                    \n",
    "    ##write out jclusterfunk lists\n",
    "    for lin, taxa in lin_to_taxa.items():\n",
    "        with open(f\"{outdir}/{lin}.csv\", 'w') as fw:\n",
    "            fw.write(\"name\\n\")\n",
    "            for tax in taxa:\n",
    "                lookup = tax.split(\"|\")[0]\n",
    "                if lookup in tax_to_coord:\n",
    "                    fw.write(f'{tax}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sequence_name', 'secondary_identifier', 'sample_date', 'epi_week', 'country', 'adm1', 'adm2', 'outer_postcode', 'is_surveillance', 'is_community', 'is_hcw', 'is_travel_history', 'travel_history', 'lineage', 'lineages_version', 'lineage_conflict', 'lineage_ambiguity_score', 'scorpio_call', 'scorpio_support', 'scorpio_conflict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "582211it [00:02, 210196.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 25143/25143 [00:09<00:00, 2684.36it/s]\n"
     ]
    }
   ],
   "source": [
    "metadata = ##METADATA_FILE\n",
    "intro_dir = ##TREE_FILES\n",
    "\n",
    "wanted_intros = [\"0_92\", \"0_190\", \"2_337\", \"0_67\", \"1_51\", \"0_322\", \"0_386\"]  \n",
    "\n",
    "make_input_files(intro_dir, wanted_intros,metadata, \"../input_files/large_lineages/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_files_small_lins(intro_list, wanted_intros,metadata, outdir):\n",
    "\n",
    "    lin_to_taxa = defaultdict(list)\n",
    "    all_taxa = set()\n",
    "    tax_to_fullname = {}\n",
    "    \n",
    "    for intro_list in os.listdir(intro_dir):\n",
    "        if intro_list.endswith(\".tsv\"):\n",
    "            tree_number = intro_list.split(\".\")[0].split(\"_\")[1][-1]\n",
    "            relevant_intros = [i for i in wanted_intros if i.startswith(tree_number)]\n",
    "            with open(os.path.join(intro_dir,intro_list)) as f:\n",
    "                data = csv.DictReader(f, delimiter=\"\\t\")\n",
    "                for line in data:\n",
    "                    if f\"{tree_number}_{line['lineage']}\" in relevant_intros:\n",
    "                        taxa = line['taxa'].split(\";\")\n",
    "                        for i in taxa:\n",
    "                            lin_to_taxa[f\"{tree_number}_{line['lineage']}\"].append(i.strip(\" \"))\n",
    "                            all_taxa.add(i.strip(\" \").split(\"|\")[0])\n",
    "                            tax_to_fullname[i.strip(\" \").split(\"|\")[0]] = i.strip(\" \")\n",
    "                    \n",
    "    taxa_to_postcode = {}\n",
    "    with open(metadata) as f:\n",
    "        data = csv.DictReader(f)\n",
    "        print(data.fieldnames)\n",
    "        for line in tqdm.tqdm(data):\n",
    "            if line['sequence_name'] in all_taxa:\n",
    "                if line['outer_postcode'] != \"\":\n",
    "                    taxa_to_postcode[line['sequence_name']] = line['outer_postcode']\n",
    "                    \n",
    "    tax_to_coord = {}\n",
    "    for tax, pc in tqdm.tqdm(taxa_to_postcode.items()):\n",
    "        try:\n",
    "            polygon = dist_to_polygon[pc]\n",
    "        except:\n",
    "            continue\n",
    "        point = find_point(polygon, pc)\n",
    "        tax_to_coord[tax] = point\n",
    "        \n",
    "    ##make traits file\n",
    "    file_name = f'{outdir}/traits.tsv'\n",
    "    with open(file_name, 'w') as fw:\n",
    "        fw.write(\"taxon\\tlatitude\\tlongitude\\n\")\n",
    "        for lin, taxa in lin_to_taxa.items():\n",
    "                for tax in taxa:\n",
    "                    lookup = tax.split(\"|\")[0]\n",
    "                    if lookup in tax_to_coord:\n",
    "                        fw.write(f\"{tax}\\t{tax_to_coord[lookup].y}\\t{tax_to_coord[lookup].x}\\n\")\n",
    "\n",
    "\n",
    "    ##write out jclusterfunk lists\n",
    "    for lin, taxa in lin_to_taxa.items():\n",
    "        with open(f\"{outdir}/jclusterfunk_lists/{lin}.csv\", 'w') as fw:\n",
    "            fw.write(\"name\\n\")\n",
    "            for tax in taxa:\n",
    "                lookup = tax.split(\"|\")[0]\n",
    "                if lookup in tax_to_coord:\n",
    "                    fw.write(f'{tax}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "['sequence_name', 'secondary_identifier', 'sample_date', 'epi_week', 'country', 'adm1', 'adm2', 'outer_postcode', 'is_surveillance', 'is_community', 'is_hcw', 'is_travel_history', 'travel_history', 'lineage', 'lineages_version', 'lineage_conflict', 'lineage_ambiguity_score', 'scorpio_call', 'scorpio_support', 'scorpio_conflict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "582211it [00:02, 213127.39it/s]\n",
      " 65%|████████████████████████████████████████████████████████████████████▏                                    | 15844/24417 [00:05<00:02, 3011.49it/s]"
     ]
    }
   ],
   "source": [
    "metadata = ##METADATA\n",
    "intro_dir = ##TREE_FILES\n",
    "\n",
    "wanted_intros = []\n",
    "for intro_list in os.listdir(intro_dir):\n",
    "    if intro_list.endswith(\".tsv\"):\n",
    "        tree_number = intro_list.split(\".\")[0].split(\"_\")[1][-1]\n",
    "        with open(os.path.join(intro_dir,intro_list)) as f:\n",
    "            data = csv.DictReader(f, delimiter=\"\\t\")\n",
    "            for line in data:\n",
    "                if f\"{tree_number}_{line['lineage']}\" not in wanted_intros:\n",
    "                    taxa = line['taxa'].split(\";\")\n",
    "                    if len(taxa) >= 5 and len(taxa) < 1500:\n",
    "                        wanted_intros.append(f\"{tree_number}_{line['lineage']}\")\n",
    "\n",
    "print(len(wanted_intros))       \n",
    "\n",
    "make_input_files_small_lins(intro_dir, wanted_intros,metadata, \"../input_files/small_lineages\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
